{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Data Aggregator and Analyzer ETL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introduction\n",
    "In today’s data-driven world, financial analysts and investors require timely access to accurate and comprehensive financial data to make informed decisions. The finance industry generates vast amounts of data from various sources, including stock markets, financial news, and company financial statements. By aggregating, analyzing, and visualizing this data, analysts and investors can identify trends, evaluate risks, and discover investment opportunities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "The objective of the Financial Data Aggregator and Analyzer project is to create an end-to-end Extract, Transform, Load (ETL) pipeline that consolidates and processes financial data from multiple sources. This pipeline will empower you to practice essential data engineering skills, such as data collection, data transformation and data loading while working with real-world financial data. By implementing this project, you will gain hands-on experience in utilizing Python, APIs, Web Scraping, and SQL to address challenges in the finance industry."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nichollastidow/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "#from googletrans import Translator\n",
    "pd.options.display.max_colwidth = 50\n",
    "import os\n",
    "import sqlite3\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Financial News: \n",
    "Scrape financial news websites from CNBC using web scraping libraries such as BeautifulSoup to collect all the headlines that are present in the page at the moment of performing the requests. Save the timestamp of the moment you realized the request in some variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A rebalance into fixed income away from equiti...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/20/a-rebala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tax-free bond trade: Finding long-term opportu...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/20/there-is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Average credit card interest rate is a record ...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/2023/06/20/credit-card-ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell boosts dividend by 15%, maintains oil ou...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/2023/06/14/shell-boosts-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chocolate is set to get more expensive as coco...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/2023/06/13/chocolate-is-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Apple's financial fundamental performance is n...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/20/apples-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Fundstrat's Tom Lee: We're not falling into a ...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/16/fundstra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Market sentiment about interest rates is drivi...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/16/market-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>The A.I. flood has gone too far too fast, says...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/15/short-th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Chart of the day: Tesla, taking stock of its s...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/15/chart-of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             headline  \\\n",
       "0   A rebalance into fixed income away from equiti...   \n",
       "1   Tax-free bond trade: Finding long-term opportu...   \n",
       "2   Average credit card interest rate is a record ...   \n",
       "3   Shell boosts dividend by 15%, maintains oil ou...   \n",
       "4   Chocolate is set to get more expensive as coco...   \n",
       "..                                                ...   \n",
       "58  Apple's financial fundamental performance is n...   \n",
       "59  Fundstrat's Tom Lee: We're not falling into a ...   \n",
       "60  Market sentiment about interest rates is drivi...   \n",
       "61  The A.I. flood has gone too far too fast, says...   \n",
       "62  Chart of the day: Tesla, taking stock of its s...   \n",
       "\n",
       "                    timestamp  \\\n",
       "0  2023-06-20 18:05:57.330004   \n",
       "1  2023-06-20 18:05:57.330004   \n",
       "2  2023-06-20 18:05:57.330004   \n",
       "3  2023-06-20 18:05:57.330004   \n",
       "4  2023-06-20 18:05:57.330004   \n",
       "..                        ...   \n",
       "58 2023-06-20 18:05:57.330004   \n",
       "59 2023-06-20 18:05:57.330004   \n",
       "60 2023-06-20 18:05:57.330004   \n",
       "61 2023-06-20 18:05:57.330004   \n",
       "62 2023-06-20 18:05:57.330004   \n",
       "\n",
       "                                                  url  \n",
       "0   https://www.cnbc.com/video/2023/06/20/a-rebala...  \n",
       "1   https://www.cnbc.com/video/2023/06/20/there-is...  \n",
       "2   https://www.cnbc.com/2023/06/20/credit-card-ra...  \n",
       "3   https://www.cnbc.com/2023/06/14/shell-boosts-d...  \n",
       "4   https://www.cnbc.com/2023/06/13/chocolate-is-s...  \n",
       "..                                                ...  \n",
       "58  https://www.cnbc.com/video/2023/06/20/apples-f...  \n",
       "59  https://www.cnbc.com/video/2023/06/16/fundstra...  \n",
       "60  https://www.cnbc.com/video/2023/06/16/market-s...  \n",
       "61  https://www.cnbc.com/video/2023/06/15/short-th...  \n",
       "62  https://www.cnbc.com/video/2023/06/15/chart-of...  \n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def scrape_financial_news_from_cnbc():\n",
    "    \"\"\"\n",
    "    Scrapes financial news from CNBC.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A DataFrame with headlines, the scrape timestamp and the URL.\n",
    "    \"\"\"\n",
    "    # Get the HTML of the CNBC homepage.\n",
    "    response = requests.get(\"https://www.cnbc.com/markets/\")\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Get the headlines on the CNBC homepage.\n",
    "    headlines = soup.find_all(\"a\", class_=\"Card-title\")\n",
    "\n",
    "    # Create lists to store the headlines and their URLs.\n",
    "    headlines_list = [headline.text.strip() for headline in headlines]\n",
    "    url_list = [headline['href'] for headline in headlines]\n",
    "\n",
    "    # Make sure to prepend the main domain to relative URLs.\n",
    "    base_url = 'https://www.cnbc.com'\n",
    "    url_list = [base_url + url if url.startswith('/') else url for url in url_list]\n",
    "\n",
    "    # Save the timestamp of the moment you realized the request.\n",
    "    timestamp = pd.Timestamp.now()\n",
    "\n",
    "    # Create a DataFrame with the headlines, the timestamp and the URLs.\n",
    "    df = pd.DataFrame({\n",
    "        'headline': headlines_list,\n",
    "        'timestamp': [timestamp] * len(headlines_list),\n",
    "        'url': url_list\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the function to scrape the data.\n",
    "    df_news = scrape_financial_news_from_cnbc()\n",
    "    # Print the DataFrame.\n",
    "    display(df_news)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Stock Market Data: \n",
    "Use Alpha Vantage API to extract stock market data. Get historical stock prices for the following companies:\n",
    "- Apple\n",
    "- Microsoft\n",
    "- Google\n",
    "- Amazon\n",
    "- Meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get alpha vantage api key\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "api_key_av = os.getenv(\"ALPHA_VANTAGE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open_price</th>\n",
       "      <th>highest_price</th>\n",
       "      <th>lowest_price</th>\n",
       "      <th>close_price</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>122.82</td>\n",
       "      <td>126.370</td>\n",
       "      <td>122.280</td>\n",
       "      <td>124.74</td>\n",
       "      <td>124.740000</td>\n",
       "      <td>35528531</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>130.28</td>\n",
       "      <td>130.900</td>\n",
       "      <td>124.170</td>\n",
       "      <td>125.07</td>\n",
       "      <td>124.706364</td>\n",
       "      <td>112117471</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>85.46</td>\n",
       "      <td>86.960</td>\n",
       "      <td>84.205</td>\n",
       "      <td>85.82</td>\n",
       "      <td>85.820000</td>\n",
       "      <td>76706040</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>89.83</td>\n",
       "      <td>91.550</td>\n",
       "      <td>89.020</td>\n",
       "      <td>89.70</td>\n",
       "      <td>89.700000</td>\n",
       "      <td>20738457</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>243.08</td>\n",
       "      <td>245.750</td>\n",
       "      <td>237.400</td>\n",
       "      <td>239.58</td>\n",
       "      <td>238.460203</td>\n",
       "      <td>25740036</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2023-06-20</td>\n",
       "      <td>124.86</td>\n",
       "      <td>127.250</td>\n",
       "      <td>124.500</td>\n",
       "      <td>125.78</td>\n",
       "      <td>125.780000</td>\n",
       "      <td>56855478</td>\n",
       "      <td>AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>2023-06-20</td>\n",
       "      <td>339.27</td>\n",
       "      <td>342.070</td>\n",
       "      <td>335.860</td>\n",
       "      <td>338.05</td>\n",
       "      <td>338.050000</td>\n",
       "      <td>26350198</td>\n",
       "      <td>MSFT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2023-06-20</td>\n",
       "      <td>123.50</td>\n",
       "      <td>125.175</td>\n",
       "      <td>122.830</td>\n",
       "      <td>123.85</td>\n",
       "      <td>123.850000</td>\n",
       "      <td>22666024</td>\n",
       "      <td>GOOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>2023-06-20</td>\n",
       "      <td>278.73</td>\n",
       "      <td>284.800</td>\n",
       "      <td>276.220</td>\n",
       "      <td>284.33</td>\n",
       "      <td>284.330000</td>\n",
       "      <td>20676920</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-20</td>\n",
       "      <td>184.69</td>\n",
       "      <td>186.100</td>\n",
       "      <td>184.445</td>\n",
       "      <td>185.01</td>\n",
       "      <td>185.010000</td>\n",
       "      <td>49751021</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  open_price  highest_price  lowest_price  close_price  \\\n",
       "579 2023-01-03      122.82        126.370       122.280       124.74   \n",
       "115 2023-01-03      130.28        130.900       124.170       125.07   \n",
       "463 2023-01-03       85.46         86.960        84.205        85.82   \n",
       "347 2023-01-03       89.83         91.550        89.020        89.70   \n",
       "231 2023-01-03      243.08        245.750       237.400       239.58   \n",
       "..         ...         ...            ...           ...          ...   \n",
       "348 2023-06-20      124.86        127.250       124.500       125.78   \n",
       "116 2023-06-20      339.27        342.070       335.860       338.05   \n",
       "232 2023-06-20      123.50        125.175       122.830       123.85   \n",
       "464 2023-06-20      278.73        284.800       276.220       284.33   \n",
       "0   2023-06-20      184.69        186.100       184.445       185.01   \n",
       "\n",
       "     adjusted_close     volume symbol  \n",
       "579      124.740000   35528531   META  \n",
       "115      124.706364  112117471   AAPL  \n",
       "463       85.820000   76706040   AMZN  \n",
       "347       89.700000   20738457   GOOG  \n",
       "231      238.460203   25740036   MSFT  \n",
       "..              ...        ...    ...  \n",
       "348      125.780000   56855478   AMZN  \n",
       "116      338.050000   26350198   MSFT  \n",
       "232      123.850000   22666024   GOOG  \n",
       "464      284.330000   20676920   META  \n",
       "0        185.010000   49751021   AAPL  \n",
       "\n",
       "[580 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_stock_prices_alphaVantage_api(symbols, start_date, end_date,api_key):\n",
    "    \"\"\"\n",
    "    Gets stock prices from Alpha Vantage API for the specified dates and symbols.\n",
    "\n",
    "    Args:\n",
    "        symbols (list): A list of stock symbols to get data for.\n",
    "        start_date (str): The start date in YYYY-MM-DD format.\n",
    "        end_date (str): The end date in YYYY-MM-DD format.\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame of stock prices.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a DataFrame to store the stock prices.\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Iterate over the symbols.\n",
    "    for symbol in symbols:\n",
    "\n",
    "        # Construct the API endpoint URL.\n",
    "        url = f\"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={symbol}&apikey={api_key}&outputsize=full\"\n",
    "\n",
    "        # Make a GET request to the API.\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Check the response status code.\n",
    "        if response.status_code == 200:\n",
    "\n",
    "            # Get the JSON response data.\n",
    "            data = json.loads(response.content.decode(\"utf-8\"))\n",
    "\n",
    "            # Iterate over the dates.\n",
    "            for date in data[\"Time Series (Daily)\"]:\n",
    "                # Check if the date is in the desired date range.\n",
    "                if start_date <= date <= end_date:\n",
    "\n",
    "                    # Get the stock price and other information.\n",
    "                    price_data = data[\"Time Series (Daily)\"][date]\n",
    "                    open_price = float(price_data['1. open'])\n",
    "                    highest_price = float(price_data['2. high'])\n",
    "                    lowest_price = float(price_data['3. low'])\n",
    "                    close_price = float(price_data['4. close'])\n",
    "                    adjusted_close = float(price_data['5. adjusted close'])\n",
    "                    volume = int(price_data['6. volume'])\n",
    "\n",
    "                    # Create a temp DataFrame and append it to main DataFrame\n",
    "                    temp_df = pd.DataFrame({\n",
    "                        'date': [pd.to_datetime(date)],\n",
    "                        'open_price': [open_price],\n",
    "                        'highest_price': [highest_price],\n",
    "                        'lowest_price': [lowest_price],\n",
    "                        'close_price': [close_price],\n",
    "                        'adjusted_close': [adjusted_close],\n",
    "                        'volume': [volume],\n",
    "                        'symbol': [symbol]})\n",
    "                    \n",
    "                    df = pd.concat([df, temp_df], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Print an error message.\n",
    "            print(f\"Error getting stock price for {symbol}\")\n",
    "\n",
    "    # Sort the DataFrame by date.\n",
    "    df = df.sort_values(by='date')\n",
    "\n",
    "    # Return the DataFrame.\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the stock symbols.\n",
    "    symbols = [\"AAPL\", \"MSFT\", \"GOOG\", \"AMZN\", \"META\"]\n",
    "\n",
    "    # api key\n",
    "    api_key = api_key_av\n",
    "\n",
    "    # Set the start and end dates.\n",
    "    start_date = \"2023-01-01\"\n",
    "    end_date = \"2023-06-20\"\n",
    "\n",
    "    # Get the stock prices.\n",
    "    df_stocks = get_stock_prices_alphaVantage_api(symbols, start_date, end_date,api_key)\n",
    "\n",
    "    # Print the DataFrame.\n",
    "    display(df_stocks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Sentiment Analysis\n",
    "Business would like to know the sentiment of the financial stocks news headlines that you extracted. The headlines are short and concise, and they reflect the latest developments and trends in the stock market. They want to know if the headlines are positive, negative, or neutral in terms of their emotional tone and impact on the investors.\n",
    "\n",
    "For this you can use a library called textblob and apply the sentiment polarity method. Save the polarity score in a new column called sentiment_score. If the result obtained is between -1 and -0.2 classify the sentiment as negative, if it is between -0.2 and 0.2 classify it as neutral, else classify it as positive. Save this classification into a new column called sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A rebalance into fixed income away from equiti...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/20/a-rebala...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tax-free bond trade: Finding long-term opportu...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/20/there-is...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Average credit card interest rate is a record ...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/2023/06/20/credit-card-ra...</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell boosts dividend by 15%, maintains oil ou...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/2023/06/14/shell-boosts-d...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chocolate is set to get more expensive as coco...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/2023/06/13/chocolate-is-s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Apple's financial fundamental performance is n...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/20/apples-f...</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Fundstrat's Tom Lee: We're not falling into a ...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/16/fundstra...</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Market sentiment about interest rates is drivi...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/16/market-s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>The A.I. flood has gone too far too fast, says...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/15/short-th...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Chart of the day: Tesla, taking stock of its s...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/15/chart-of...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             headline  \\\n",
       "0   A rebalance into fixed income away from equiti...   \n",
       "1   Tax-free bond trade: Finding long-term opportu...   \n",
       "2   Average credit card interest rate is a record ...   \n",
       "3   Shell boosts dividend by 15%, maintains oil ou...   \n",
       "4   Chocolate is set to get more expensive as coco...   \n",
       "..                                                ...   \n",
       "58  Apple's financial fundamental performance is n...   \n",
       "59  Fundstrat's Tom Lee: We're not falling into a ...   \n",
       "60  Market sentiment about interest rates is drivi...   \n",
       "61  The A.I. flood has gone too far too fast, says...   \n",
       "62  Chart of the day: Tesla, taking stock of its s...   \n",
       "\n",
       "                    timestamp  \\\n",
       "0  2023-06-20 18:05:57.330004   \n",
       "1  2023-06-20 18:05:57.330004   \n",
       "2  2023-06-20 18:05:57.330004   \n",
       "3  2023-06-20 18:05:57.330004   \n",
       "4  2023-06-20 18:05:57.330004   \n",
       "..                        ...   \n",
       "58 2023-06-20 18:05:57.330004   \n",
       "59 2023-06-20 18:05:57.330004   \n",
       "60 2023-06-20 18:05:57.330004   \n",
       "61 2023-06-20 18:05:57.330004   \n",
       "62 2023-06-20 18:05:57.330004   \n",
       "\n",
       "                                                  url  sentiment_score  \\\n",
       "0   https://www.cnbc.com/video/2023/06/20/a-rebala...         0.100000   \n",
       "1   https://www.cnbc.com/video/2023/06/20/there-is...         0.000000   \n",
       "2   https://www.cnbc.com/2023/06/20/credit-card-ra...         0.116667   \n",
       "3   https://www.cnbc.com/2023/06/14/shell-boosts-d...         0.000000   \n",
       "4   https://www.cnbc.com/2023/06/13/chocolate-is-s...         0.000000   \n",
       "..                                                ...              ...   \n",
       "58  https://www.cnbc.com/video/2023/06/20/apples-f...        -0.050000   \n",
       "59  https://www.cnbc.com/video/2023/06/16/fundstra...        -0.100000   \n",
       "60  https://www.cnbc.com/video/2023/06/16/market-s...         0.000000   \n",
       "61  https://www.cnbc.com/video/2023/06/15/short-th...         0.150000   \n",
       "62  https://www.cnbc.com/video/2023/06/15/chart-of...         0.000000   \n",
       "\n",
       "   sentiment  \n",
       "0    Neutral  \n",
       "1    Neutral  \n",
       "2    Neutral  \n",
       "3    Neutral  \n",
       "4    Neutral  \n",
       "..       ...  \n",
       "58   Neutral  \n",
       "59   Neutral  \n",
       "60   Neutral  \n",
       "61   Neutral  \n",
       "62   Neutral  \n",
       "\n",
       "[63 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def categorize_polarity(polarity):\n",
    "    \"\"\"\n",
    "    Classifies the sentiment as positive, neutral or negative based on polarity.\n",
    "\n",
    "    Args:\n",
    "        polarity (float): The polarity score from TextBlob.\n",
    "\n",
    "    Returns:\n",
    "        str: The sentiment classification.\n",
    "    \"\"\"\n",
    "\n",
    "    if polarity < -0.2:\n",
    "        return \"Negative\"\n",
    "    elif polarity <= 0.2:\n",
    "        return \"Neutral\"\n",
    "    else:\n",
    "        return \"Positive\"\n",
    "\n",
    "def analyze_sentiment(df_news):\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of news headlines.\n",
    "\n",
    "    Args:\n",
    "        df_news (DataFrame): The news headlines.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The DataFrame with the sentiment analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Copy the DataFrame.\n",
    "    df = df_news.copy()\n",
    "\n",
    "    # Get the sentiment polarity of the headlines.\n",
    "    df['sentiment_score'] = df['headline'].apply(lambda headline: TextBlob(headline).sentiment.polarity)\n",
    "\n",
    "    # Categorize the sentiment.\n",
    "    df['sentiment'] = df['sentiment_score'].apply(categorize_polarity)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Analyze the sentiment of the news headlines.\n",
    "    df_news = analyze_sentiment(df_news)\n",
    "\n",
    "    # Print the DataFrame with sentiment analysis.\n",
    "    display(df_news)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Relevant Words\n",
    "Business wants to know which might be the most relevant words for each headline. For this you can use the word_tokenize function from nltk.tokenize library. Create a column called relevant_words to save the result for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>url</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>relevant_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A rebalance into fixed income away from equiti...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/20/a-rebala...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[A, rebalance, into, fixed, income, away, from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tax-free bond trade: Finding long-term opportu...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/20/there-is...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Tax-free, bond, trade, :, Finding, long-term,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Average credit card interest rate is a record ...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/2023/06/20/credit-card-ra...</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Average, credit, card, interest, rate, is, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell boosts dividend by 15%, maintains oil ou...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/2023/06/14/shell-boosts-d...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Shell, boosts, dividend, by, 15, %, ,, mainta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chocolate is set to get more expensive as coco...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/2023/06/13/chocolate-is-s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Chocolate, is, set, to, get, more, expensive,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Apple's financial fundamental performance is n...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/20/apples-f...</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Apple, 's, financial, fundamental, performanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Fundstrat's Tom Lee: We're not falling into a ...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/16/fundstra...</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Fundstrat, 's, Tom, Lee, :, We, 're, not, fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Market sentiment about interest rates is drivi...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/16/market-s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Market, sentiment, about, interest, rates, is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>The A.I. flood has gone too far too fast, says...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/15/short-th...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[The, A.I, ., flood, has, gone, too, far, too,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Chart of the day: Tesla, taking stock of its s...</td>\n",
       "      <td>2023-06-20 18:05:57.330004</td>\n",
       "      <td>https://www.cnbc.com/video/2023/06/15/chart-of...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>[Chart, of, the, day, :, Tesla, ,, taking, sto...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             headline  \\\n",
       "0   A rebalance into fixed income away from equiti...   \n",
       "1   Tax-free bond trade: Finding long-term opportu...   \n",
       "2   Average credit card interest rate is a record ...   \n",
       "3   Shell boosts dividend by 15%, maintains oil ou...   \n",
       "4   Chocolate is set to get more expensive as coco...   \n",
       "..                                                ...   \n",
       "58  Apple's financial fundamental performance is n...   \n",
       "59  Fundstrat's Tom Lee: We're not falling into a ...   \n",
       "60  Market sentiment about interest rates is drivi...   \n",
       "61  The A.I. flood has gone too far too fast, says...   \n",
       "62  Chart of the day: Tesla, taking stock of its s...   \n",
       "\n",
       "                    timestamp  \\\n",
       "0  2023-06-20 18:05:57.330004   \n",
       "1  2023-06-20 18:05:57.330004   \n",
       "2  2023-06-20 18:05:57.330004   \n",
       "3  2023-06-20 18:05:57.330004   \n",
       "4  2023-06-20 18:05:57.330004   \n",
       "..                        ...   \n",
       "58 2023-06-20 18:05:57.330004   \n",
       "59 2023-06-20 18:05:57.330004   \n",
       "60 2023-06-20 18:05:57.330004   \n",
       "61 2023-06-20 18:05:57.330004   \n",
       "62 2023-06-20 18:05:57.330004   \n",
       "\n",
       "                                                  url  sentiment_score  \\\n",
       "0   https://www.cnbc.com/video/2023/06/20/a-rebala...         0.100000   \n",
       "1   https://www.cnbc.com/video/2023/06/20/there-is...         0.000000   \n",
       "2   https://www.cnbc.com/2023/06/20/credit-card-ra...         0.116667   \n",
       "3   https://www.cnbc.com/2023/06/14/shell-boosts-d...         0.000000   \n",
       "4   https://www.cnbc.com/2023/06/13/chocolate-is-s...         0.000000   \n",
       "..                                                ...              ...   \n",
       "58  https://www.cnbc.com/video/2023/06/20/apples-f...        -0.050000   \n",
       "59  https://www.cnbc.com/video/2023/06/16/fundstra...        -0.100000   \n",
       "60  https://www.cnbc.com/video/2023/06/16/market-s...         0.000000   \n",
       "61  https://www.cnbc.com/video/2023/06/15/short-th...         0.150000   \n",
       "62  https://www.cnbc.com/video/2023/06/15/chart-of...         0.000000   \n",
       "\n",
       "   sentiment                                     relevant_words  \n",
       "0    Neutral  [A, rebalance, into, fixed, income, away, from...  \n",
       "1    Neutral  [Tax-free, bond, trade, :, Finding, long-term,...  \n",
       "2    Neutral  [Average, credit, card, interest, rate, is, a,...  \n",
       "3    Neutral  [Shell, boosts, dividend, by, 15, %, ,, mainta...  \n",
       "4    Neutral  [Chocolate, is, set, to, get, more, expensive,...  \n",
       "..       ...                                                ...  \n",
       "58   Neutral  [Apple, 's, financial, fundamental, performanc...  \n",
       "59   Neutral  [Fundstrat, 's, Tom, Lee, :, We, 're, not, fal...  \n",
       "60   Neutral  [Market, sentiment, about, interest, rates, is...  \n",
       "61   Neutral  [The, A.I, ., flood, has, gone, too, far, too,...  \n",
       "62   Neutral  [Chart, of, the, day, :, Tesla, ,, taking, sto...  \n",
       "\n",
       "[63 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def extract_relevant_words(df):\n",
    "    \"\"\"\n",
    "    Extracts relevant words from the headlines.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame containing the headlines.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The original DataFrame with a new column containing the tokenized headlines.\n",
    "    \"\"\"\n",
    "    # Tokenize the headlines and store the result in a new column.\n",
    "    df['relevant_words'] = df['headline'].apply(word_tokenize)\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Extract the relevant words.\n",
    "    df_news = extract_relevant_words(df_news)\n",
    "    # Print the DataFrame.\n",
    "    display(df_news)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Headline Translation\n",
    "Business wants to translate the headlines to Spanish and Italian; it seems they are working on some interesting projects for new markets. Translate the headlines to these two languages. You can use googletrans library to achieve this. Please save the translated headlines in two new columns headline_spanish and headline_it for saving translated headlines to Spanish and to Italian respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def translate_headlines(df):\n",
    "#   \"\"\"\n",
    "#   Translates the headlines in a DataFrame to Spanish and Italian.\n",
    "\n",
    "#   Args:\n",
    "#     df (DataFrame): DataFrame containing the headlines.\n",
    "\n",
    "#   Returns:\n",
    "#     A DataFrame with the translated headlines in two new columns: `headline_spanish` and `headline_it`.\n",
    "#   \"\"\"\n",
    "#   # Create a translator object.\n",
    "#   translator = Translator()\n",
    "\n",
    "#   # Translate the headlines to Spanish and store the result in a new column.\n",
    "#   df['headline_spanish'] = df['headline'].apply(lambda x: translator.translate(x, dest='es').text)\n",
    "\n",
    "#   # Translate the headlines to Italian and store the result in a new column.\n",
    "#   df['headline_it'] = df['headline'].apply(lambda x: translator.translate(x, dest='it').text)\n",
    "\n",
    "#   # Return the DataFrame.\n",
    "#   return df\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Extract the relevant words.\n",
    "#     df_news = translate_headlines(df_news)\n",
    "#     # Print the DataFrame.\n",
    "#     display(df_news)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4) Save the Data\n",
    "Save data from scrapped headlines into a csv file called headlines_data.csv under the path: data/headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_headlines_to_csv(df, path='data/headlines/headlines_data.csv'):\n",
    "    \"\"\"\n",
    "    Saves headlines data into a CSV file.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame with the headlines data.\n",
    "        path (str): The path to save the CSV file to. By default, it's 'data/headlines/headlines_data.csv'.\n",
    "    \"\"\"\n",
    "    # Check if the directory exists, if not create it.\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    # Save the DataFrame to a CSV file.\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Save the data to a CSV file.\n",
    "    save_headlines_to_csv(df_news)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the stock data into a CSV file called stocks_data.csv under the path data/stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_stock_info_to_csv(df, path='data/stocks/stocks_data.csv'):\n",
    "    \"\"\"\n",
    "    Saves stock info data into a CSV file.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame with the stocks data.\n",
    "        path (str): The path to save the CSV file to. By default, it's 'data/stocks/stocks_data.csv'.\n",
    "    \"\"\"\n",
    "    # Check if the directory exists, if not create it.\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "    # Save the DataFrame to a CSV file.\n",
    "    df.to_csv(path, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Save the data to a CSV file.\n",
    "    save_stock_info_to_csv(df_stocks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Create SQLite Database: Install SQLite in your machine and create a database called etl_extended_case.\n",
    "2) Create Tables: Create two tables headlines and stocks for loading headlines and stocks data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to SQLite database (it will be created if it doesn't exist)\n",
    "conn = sqlite3.connect('etl_extended_case.db')\n",
    "\n",
    "# Create a cursor object\n",
    "c = conn.cursor()\n",
    "\n",
    "# Create the 'stock_prices' table\n",
    "c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS stock_prices (\n",
    "        date TEXT,\n",
    "        open_price FLOAT,\n",
    "        highest_price FLOAT,\n",
    "        lowest_price FLOAT,\n",
    "        close_price FLOAT,\n",
    "        adjusted_close FLOAT,\n",
    "        volume INTEGER,\n",
    "        symbol TEXT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Create the 'headline_news' table\n",
    "c.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS headline_news (\n",
    "        headline TEXT,\n",
    "        timestamp TEXT,\n",
    "        url TEXT,\n",
    "        sentiment_score FLOAT,\n",
    "        sentiment TEXT,\n",
    "        relevant_words TEXT,\n",
    "        headline_spanish TEXT,\n",
    "        headline_it TEXT\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "# Open the files and insert data into tables\n",
    "with open('data/stocks/stocks_data.csv', 'r') as f:\n",
    "    stocks_reader = csv.reader(f)\n",
    "    for row in stocks_reader:\n",
    "        c.execute(\"\"\" INSERT INTO stock_prices VALUES (?,?,?,?,?,?,?,?) \"\"\", row)\n",
    "\n",
    "with open('data/headlines/headlines_data.csv', 'r') as f:\n",
    "    headlines_reader = csv.reader(f)\n",
    "    for headline in headlines_reader:\n",
    "        c.execute(\"\"\" INSERT INTO headline_news VALUES (?,?,?,?,?,?,?,?) \"\"\", headline)\n",
    "\n",
    "# Commit the transactions\n",
    "conn.commit()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that the data has been loaded correctly\n",
    "conn = sqlite3.connect('etl_extended_case.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "# Select first 5 rows from stock_prices table\n",
    "c.execute(\"SELECT * FROM stock_prices LIMIT 5\")\n",
    "stock_prices_data = c.fetchall()\n",
    "\n",
    "# Select first 5 rows from headline_news table\n",
    "c.execute(\"SELECT * FROM headline_news LIMIT 5\")\n",
    "headline_news_data = c.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Print the data\n",
    "print(\"First 5 rows of stock_prices:\")\n",
    "for row in stock_prices_data:\n",
    "    display(row)\n",
    "\n",
    "print(\"\\nFirst 5 rows of headline_news:\")\n",
    "for row in headline_news_data:\n",
    "    display(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'google.cloud.sql' has no attribute 'Client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m user \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mDB_USER\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m password \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mDB_PASS\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m load_csv_to_cloud_sql(instance_name,db_name,csv_path,user,password,region)\n",
      "Cell \u001b[0;32mIn[32], line 11\u001b[0m, in \u001b[0;36mload_csv_to_cloud_sql\u001b[0;34m(instance_name, database_name, csv_file_path, username, password, region)\u001b[0m\n\u001b[1;32m      8\u001b[0m credentials, project_id \u001b[39m=\u001b[39m google\u001b[39m.\u001b[39mauth\u001b[39m.\u001b[39mdefault()\n\u001b[1;32m     10\u001b[0m \u001b[39m# Create a Cloud SQL client\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m sql_client \u001b[39m=\u001b[39m sql\u001b[39m.\u001b[39;49mClient(project\u001b[39m=\u001b[39mproject_id, credentials\u001b[39m=\u001b[39mcredentials)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Create a new Cloud SQL instance\u001b[39;00m\n\u001b[1;32m     14\u001b[0m instance \u001b[39m=\u001b[39m sql_client\u001b[39m.\u001b[39mcreate_instance(instance_name, region, \u001b[39m\"\u001b[39m\u001b[39mPOSTGRES\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'google.cloud.sql' has no attribute 'Client'"
     ]
    }
   ],
   "source": [
    "import google.auth\n",
    "from google.cloud import sql\n",
    "from google.cloud.sql.connector import connector\n",
    "import pandas as pd\n",
    "\n",
    "def load_csv_to_cloud_sql(instance_name, database_name, csv_file_path, username, password, region):\n",
    "    # Authenticate with Google Cloud\n",
    "    credentials, project_id = google.auth.default()\n",
    "\n",
    "    # Create a Cloud SQL client\n",
    "    sql_client = sql.Client(project=project_id, credentials=credentials)\n",
    "\n",
    "    # Create a new Cloud SQL instance\n",
    "    instance = sql_client.create_instance(instance_name, region, \"POSTGRES\")\n",
    "\n",
    "    # Connect to the instance using the Cloud SQL connector\n",
    "    conn = connector.connect(instance.connection_name, user=username, password=password, database=database_name)\n",
    "\n",
    "    # Load data from the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Insert the data into the Cloud SQL database\n",
    "    cursor = conn.cursor()\n",
    "    for index, row in df.iterrows():\n",
    "        values = tuple(row)\n",
    "        placeholders = \",\".join([\"%s\"] * len(values))\n",
    "        query = f\"INSERT INTO table_name VALUES ({placeholders})\"\n",
    "        cursor.execute(query, values)\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Data imported successfully!\")\n",
    "if __name__ == \"__main__\":\n",
    "    instance_name = os.getenv(\"INSTANCE_CONNECTION_NAME\")\n",
    "    db_name = os.getenv(\"DB_NAME\")\n",
    "    csv_path = 'data/stocks/stocks_data.csv'\n",
    "    region = os.getenv(\"REGION_NAME\")\n",
    "    user = os.getenv(\"DB_USER\")\n",
    "    password = os.getenv(\"DB_PASS\")\n",
    "    load_csv_to_cloud_sql(instance_name,db_name,csv_path,user,password,region)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql+pg8000://)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud.sql.connector import Connector, IPTypes\n",
    "import pg8000\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "\n",
    "def connect_with_connector() -> sqlalchemy.engine.base.Engine:\n",
    "    \"\"\"\n",
    "    Initializes a connection pool for a Cloud SQL instance of Postgres.\n",
    "\n",
    "    Uses the Cloud SQL Python Connector package.\n",
    "    \"\"\"\n",
    "    # Note: Saving credentials in environment variables is convenient, but not\n",
    "    # secure - consider a more secure solution such as\n",
    "    # Cloud Secret Manager (https://cloud.google.com/secret-manager) to help\n",
    "    # keep secrets safe.\n",
    "\n",
    "    instance_connection_name = os.environ[\n",
    "        \"INSTANCE_CONNECTION_NAME\"\n",
    "    ]  # e.g. 'project:region:instance'\n",
    "    db_user = os.environ[\"DB_USER\"]  # e.g. 'my-db-user'\n",
    "    db_pass = os.environ[\"DB_PASS\"]  # e.g. 'my-db-password'\n",
    "    db_name = os.environ[\"DB_NAME\"]  # e.g. 'my-database'\n",
    "\n",
    "    ip_type = IPTypes.PRIVATE if os.environ.get(\"PRIVATE_IP\") else IPTypes.PUBLIC\n",
    "\n",
    "    # initialize Cloud SQL Python Connector object\n",
    "    connector = Connector()\n",
    "\n",
    "    def getconn() -> pg8000.dbapi.Connection:\n",
    "        conn: pg8000.dbapi.Connection = connector.connect(\n",
    "            instance_connection_name,\n",
    "            \"pg8000\",\n",
    "            user=db_user,\n",
    "            password=db_pass,\n",
    "            db=db_name,\n",
    "            ip_type=ip_type,\n",
    "        )\n",
    "        return conn\n",
    "\n",
    "    # The Cloud SQL Python Connector can be used with SQLAlchemy\n",
    "    # using the 'creator' argument to 'create_engine'\n",
    "    pool = sqlalchemy.create_engine(\n",
    "        \"postgresql+pg8000://\",\n",
    "        creator=getconn,\n",
    "        \n",
    "    )\n",
    "    return pool\n",
    "connect_with_connector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'instance_connection_string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpsycopg2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Connect to the instance using psycopg2\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m conn \u001b[39m=\u001b[39m psycopg2\u001b[39m.\u001b[39mconnect(instance_connection_string)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Create a cursor object\u001b[39;00m\n\u001b[1;32m      7\u001b[0m cursor \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mcursor()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'instance_connection_string' is not defined"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connect to the instance using psycopg2\n",
    "conn = psycopg2.connect(instance_connection_string)\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Define the SQL query to create the table\n",
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS stocks_data (\n",
    "    date DATE,\n",
    "    open FLOAT,\n",
    "    high FLOAT,\n",
    "    low FLOAT,\n",
    "    close FLOAT,\n",
    "    adjusted_close FLOAT,\n",
    "    volume BIGINT,\n",
    "    ticker TEXT\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query to create the table\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Commit the transaction\n",
    "conn.commit()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def load_csv_to_cloud_sql(csv_file_path):\n",
    "    # Get the instance connection string and other parameters from environment variables\n",
    "    instance_connection_string = os.getenv(\"DB_CONNECTION_GCP\")\n",
    "    database_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "    # Connect to the instance using psycopg2\n",
    "    conn = psycopg2.connect(instance_connection_string)\n",
    "    \n",
    "    # Create a cursor object\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Define the SQL query to create the table\n",
    "    create_table_query = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS stocks_data (\n",
    "    date DATE,\n",
    "    open FLOAT,\n",
    "    high FLOAT,\n",
    "    low FLOAT,\n",
    "    close FLOAT,\n",
    "    adjusted_close FLOAT,\n",
    "    volume BIGINT,\n",
    "    ticker TEXT\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the SQL query to create the table\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "    # Commit the transaction\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "    # Load data from the CSV file into a Pandas DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Insert the data into the Cloud SQL database\n",
    "    cursor = conn.cursor()\n",
    "    for index, row in df.iterrows():\n",
    "        values = tuple(row)\n",
    "        placeholders = \",\".join([\"%s\"] * len(values))\n",
    "        query = f\"INSERT INTO stocks_data VALUES ({placeholders})\"\n",
    "        cursor.execute(query, values)\n",
    "    conn.commit()\n",
    "\n",
    "    # Close the connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Data imported successfully!\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = 'data/stocks/stocks_data.csv'\n",
    "    load_csv_to_cloud_sql(csv_file_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date    open     high      low   close  adjusted_close     volume  \\\n",
      "0  2023-06-20  278.73  284.800  276.220  284.33          284.33   20676920   \n",
      "1  2023-06-20  124.86  127.250  124.500  125.78          125.78   56855478   \n",
      "2  2023-06-20  123.50  125.175  122.830  123.85          123.85   22666024   \n",
      "3  2023-06-20  184.69  186.100  184.445  185.01          185.01   49751021   \n",
      "4  2023-06-20  339.27  342.070  335.860  338.05          338.05   26350198   \n",
      "5  2023-06-16  126.70  126.700  123.790  124.06          124.06   56699200   \n",
      "6  2023-06-16  127.71  127.900  125.300  125.49          125.49   84247104   \n",
      "7  2023-06-16  284.75  287.850  280.130  281.00          281.00   43127731   \n",
      "8  2023-06-16  126.70  126.700  123.790  124.06          124.06   56699200   \n",
      "9  2023-06-16  186.73  186.990  184.270  184.92          184.92  101256225   \n",
      "\n",
      "  ticker  \n",
      "0   META  \n",
      "1   AMZN  \n",
      "2   GOOG  \n",
      "3   AAPL  \n",
      "4   MSFT  \n",
      "5   GOOG  \n",
      "6   AMZN  \n",
      "7   META  \n",
      "8   GOOG  \n",
      "9   AAPL  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def fetch_and_print_records():\n",
    "    # Get the instance connection string from environment variables\n",
    "    instance_connection_string = os.getenv(\"DB_CONNECTION_GCP\")\n",
    "\n",
    "    # Connect to the instance using psycopg2\n",
    "    conn = psycopg2.connect(instance_connection_string)\n",
    "\n",
    "    # Create a cursor object\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Define a SQL query to fetch the first 10 records from the stocks_data table\n",
    "    fetch_query = \"SELECT * FROM stocks_data ORDER BY date DESC LIMIT 10;\"\n",
    "\n",
    "    # Execute the query\n",
    "    cursor.execute(fetch_query)\n",
    "\n",
    "    # Fetch the records\n",
    "    records = cursor.fetchall()\n",
    "\n",
    "    # Convert records to DataFrame for better visualization\n",
    "    df = pd.DataFrame(records, columns=['date', 'open', 'high', 'low', 'close', 'adjusted_close', 'volume', 'ticker'])\n",
    "\n",
    "    # Print the records\n",
    "    print(df)\n",
    "\n",
    "    # Close the connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fetch_and_print_records()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# from sqlalchemy import create_engine, MetaData, Table, Column, String, Float, Integer\n",
    "# from google.cloud.sql.connector import Connector, IPTypes\n",
    "\n",
    "# try:\n",
    "#     \"\"\"Initializes a connection pool for a Google Cloud SQL instance of MySQL \"\"\"\n",
    "#     instance_connection_name = os.environ.get(\"INSTANCE_CONNECTION_NAME\")\n",
    "#     db_user = os.environ.get(\"DB_USER\")\n",
    "#     db_pass = os.environ.get(\"DB_PASS\")\n",
    "#     db_name = os.environ.get(\"DB_NAME\")\n",
    "\n",
    "#     ip_type = IPTypes.PRIVATE if os.getenv(\"PRIVATE_IP\") else IPTypes.PUBLIC\n",
    "\n",
    "#     connector = Connector(ip_type)\n",
    "\n",
    "#     engine = create_engine(f\"mysql+mysqldb://{db_user}:{db_pass}@/{db_name}?unix_socket=/cloudsql/{instance_connection_name}\")\n",
    "\n",
    "#     # Create metadata instance\n",
    "#     metadata = MetaData()\n",
    "\n",
    "#     # Define tables\n",
    "#     stocks_data = Table( 'table1', metadata,\n",
    "#     Column('date',String(10), primary_key=True),\n",
    "#     Column('symbol', String(10), primary_key=True),\n",
    "#     Column('open_price', Float),\n",
    "#     Column('highest_price', Float),\n",
    "#     Column('lowest_price', Float),\n",
    "#     Column('close_price', Float),\n",
    "#     Column('adjusted_close', Float),\n",
    "#     Column('volume', Integer)\n",
    "#     )\n",
    "\n",
    "#     headline_news = Table(\n",
    "#     'table2', metadata,\n",
    "#     Column('headline', String, primary_key=True),\n",
    "#     Column('timestamp', String(10), primary_key=True),\n",
    "#     Column('url', String),\n",
    "#     Column('sentiment_score', Float),\n",
    "#     Column('sentiment', String),\n",
    "#     Column('relevant_words', String),\n",
    "#     Column('headline_spanish', String),\n",
    "#     Column('headline_it', String)\n",
    "#     )\n",
    "\n",
    "#     # Create tables\n",
    "#     metadata.create_all(engine)\n",
    "\n",
    "#     # Load the stocks data into a DataFrame\n",
    "#     with open('stocks_path', 'r') as f:\n",
    "#         stocks_df = pd.read_csv(f)\n",
    "#     # Write stocks data into stocks table in database\n",
    "#     stocks_df.to_sql('table1', engine, if_exists='append', index=False)\n",
    "\n",
    "#     # Load the headlines data into a DataFrame\n",
    "#     with open('headlines_path', 'r') as f:\n",
    "#         headlines_df = pd.read_csv(f)\n",
    "\n",
    "#     # Write headlines data into headlines table in database\n",
    "#     headlines_df.to_sql('table2', engine, if_exists='append', index=False)\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred when loading data into Google Cloud SQL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
